/*
    Copyright (c) 2008 Soren Harward <stharward@gmail.com>

    Pretty much all of this code is pulled right out of Mirage decoder, by
    Dominik Schnitzer <dominik@schnitzer.at>, which itself is derived from the
    "decodebin" example in the GStreamer documentation.

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 2 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <http://www.gnu.org/licenses/>.
*/

/* There isn't actually any C++ code in this file, other than
 * what is generated by the MRSDEBUG() and MRSWARN() macros.  */

#include "gst-decode.h"

#ifdef MARSYAS_GSTREAMER

#include "gst-decode.h"
#include <gst/gst.h>
#include <glib.h>
#include <string.h>

static void cb_newpad (GstElement *decodebin, GstPad *pad, gboolean last, GstElement *audio) {
    GstCaps *caps;
    GstStructure *str;
    GstPad *audiopad;

    /* only link once */
    audiopad = gst_element_get_pad (audio, "sink");
    if (GST_PAD_IS_LINKED (audiopad)) {
        g_object_unref (audiopad);
        return;
    }

    /* check media type */
    caps = gst_pad_get_caps (pad);
    str = gst_caps_get_structure (caps, 0);
    if (!g_strrstr (gst_structure_get_name (str), "audio")) {
        gst_caps_unref (caps);
        gst_object_unref (audiopad);
        return;
    }
    gst_caps_unref (caps);

    /* link the pads */
    gst_pad_link (pad, audiopad);
}

void handoff (GstElement* identity, GstBuffer* frame, gstreamerFrames* frameData) {
    if (GST_BUFFER_SIZE(frame) == 0) {
        return;
    }

    frameData->frameCount += 1;
    frameData->totalSize += GST_BUFFER_SIZE(frame);

    mrs_real* values = g_new(mrs_real,GST_BUFFER_SIZE(frame)/sizeof(mrs_real));
    memcpy((void*)values, (void*)GST_BUFFER_DATA(frame), GST_BUFFER_SIZE(frame));
    frameData->frameList = g_list_append(frameData->frameList, (gpointer)values);

    int* fc = g_new(int,1);
    *fc = GST_BUFFER_SIZE(frame);
    frameData->frameSize = g_list_append(frameData->frameSize, (gpointer)fc);
}

GstElement* gstreamer_init(const gchar *filename, gstreamerFrames* data) {
    // init GStreamer
    gst_init (NULL, NULL);

    // create elements of the pipeline
    GstElement *audio = gst_bin_new ("audiobin");
    GstElement *pipeline = gst_pipeline_new ("pipeline");
    GstElement *src = gst_element_factory_make ("filesrc", "source");
    GstElement *dec = gst_element_factory_make ("decodebin", "decoder");
    GstElement *conv = gst_element_factory_make ("audioconvert", "aconv");
    GstPad *audiopad = gst_element_get_pad(conv, "sink");
    // Always return audio that is 64-bit-float (same as mrs_real) at 44100 in stereo
    GstCaps *filter_float_caps = gst_caps_new_simple("audio/x-raw-float",
                                                        "width", G_TYPE_INT, sizeof(mrs_real)*8,
                                                        "rate", G_TYPE_INT, 44100,
                                                        "channels", G_TYPE_INT, 2,
                                                        NULL);
    GstElement *filt_float = gst_element_factory_make("capsfilter", "filt_float");
    GstElement *monitor = gst_element_factory_make ("identity", "idmonitor");
    GstElement *sink = gst_element_factory_make ("fakesink", "sink");

    // set up elements as needed
    g_object_set(G_OBJECT(src), "location", filename, NULL);
    g_object_set(G_OBJECT(filt_float), "caps", filter_float_caps, NULL);
    g_signal_connect(dec, "new-decoded-pad", G_CALLBACK(cb_newpad), audio);
    g_signal_connect(monitor, "handoff", G_CALLBACK(handoff), data);

    // link up the pipeline
    gst_bin_add_many (GST_BIN (pipeline), src, dec, NULL);
    gst_element_link (src, dec);

    // link up the audio output bins
    gst_bin_add_many (GST_BIN (audio), conv, filt_float, monitor, sink, NULL);
    gst_element_link_many (conv, filt_float, monitor, sink, NULL);
    gst_element_add_pad (audio, gst_ghost_pad_new("sink", audiopad));
    gst_object_unref (audiopad);
    gst_bin_add (GST_BIN (pipeline), audio);

    return pipeline;
}

void gstreamer_cleanup(GstElement* pipeline) {
    gst_element_set_state (pipeline, GST_STATE_NULL);
    gst_object_unref (GST_OBJECT (pipeline));
}

audioVector gst_decode_file(const gchar *filename) {
    gstreamerFrames* data = g_new0(gstreamerFrames,1);
    GstElement* pipeline = gstreamer_init(filename, data);
    gchar msg[100]; // short character array for diagnostic messages

    // run the decode
    gst_element_set_state(pipeline, GST_STATE_PLAYING);
    g_snprintf(msg, 100, "decoding %s\n", filename);
    MRSDEBUG(msg);

    GstBus* bus = gst_pipeline_get_bus(GST_PIPELINE(pipeline));
    GstMessage* message = 0;
    gboolean decoding = TRUE;
    while (decoding) {
        message = gst_bus_poll(bus, GST_MESSAGE_ANY, -1);
        if (message == 0)
            continue;

        switch (GST_MESSAGE_TYPE(message)) {
            case GST_MESSAGE_ERROR: {
                GError *err;
                gchar *debug;

                gst_message_parse_error(message, &err, &debug);
                g_snprintf(msg, 100, "GStreamer decode error: %s\n", err->message);
                MRSWARN(msg);
                g_error_free(err);
                g_free(debug);
                g_free(msg);
                decoding = FALSE;

                break;
            }
            case GST_MESSAGE_EOS: {
                g_snprintf(msg, 100, "End of stream\n");
                MRSDEBUG(msg);
                decoding = FALSE;
                break;
            }
            default:
                break;
        }
    }
    g_snprintf(msg, 100, "got %d frames of audio\n", data->frameCount);
    MRSDEBUG(msg);
    g_snprintf(msg, 100, "%d bytes of audio data\n", data->totalSize);
    MRSDEBUG(msg);

    gst_object_unref(bus);
    gstreamer_cleanup(pipeline);

    // condense all of the data frames into one big array
    mrs_real* alldata = g_new0(mrs_real, data->totalSize/sizeof(mrs_real));
    mrs_real* copyLoc = alldata;

    GList *dl, *sl;
    int fsize = 0;
    int frameN = 0;
    for (dl = data->frameList, sl = data->frameSize; (dl != 0) && (sl != 0); dl = g_list_next(dl), sl = g_list_next(sl)) {
        fsize = *((int*)sl->data);
        memcpy((void*)copyLoc, (void*)dl->data, fsize);
        copyLoc += fsize/sizeof(mrs_real);
        g_free(dl->data);
        g_free(sl->data);
    }
    g_snprintf(msg, 100, "finished condensing data\n");
    MRSDEBUG(msg);
    g_list_free(data->frameList);
    g_list_free(data->frameSize);

    audioVector r = {alldata, data->totalSize/sizeof(mrs_real)};
    return r;
}

#endif //MARSYAS_GSTREAMER
